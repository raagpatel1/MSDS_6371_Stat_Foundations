g6 = ggplot(HSB,aes(x = science, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Science")
g7 = ggplot(HSB,aes(x = read, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Reading")
ggarrange(g5,g6,g7, nrow = 3, ncol = 1)
g5 = ggplot(HSB,aes(x = math, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Math")
g6 = ggplot(HSB,aes(x = science, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Science")
g7 = ggplot(HSB,aes(x = read, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Reading")
g8 = ggplot(HSB, aes(x = math, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science")
g9 = ggplot(HSB, aes(x = read, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Reading V Science")
ggarrange(g5,g6,g7,g8,g9, nrow = 3, ncol = 2)
fit2 = lm(science ~ math + read, data = HSB)
## Step 3 INTERPRETATION
summary(fit2)
confint(fit)
fit2 = lm(science ~ math + read, data = HSB)
## Step 3 INTERPRETATION
summary(fit2)
confint(fit2)
correlation = round(cor(HSB[,7:11]),1)
ggcorrplot(correlation, type = "lower",lab = TRUE)
ggplot(HSB, aes(x = math, y = science, color = ses)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science W/ SES")
ggplot(HSB, aes())
summary(HSB)
head(HSB)
HSB = within(HSB, ses <- relevel(ses, ref = 3))
fit = lm(science ~ math + ses, data = HSB)
summary(fit)
## Step 2/3 MODEL
# mu(science|ses, math) = Bo + B1 SES(1) + B2 SES(2) + B3 Math
summary(HSB)
head(HSB)
HSB = within(HSB, ses <- relevel(ses, ref = 3))
fit = lm(science ~ math + ses, data = HSB)
summary(fit)
## Step 4 ASSUMPTIONS
# Normality
g1 = ggplot(HSB,aes(x = math, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Math")
g2 = ggplot(HSB,aes(x = science, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Science")
ggarrange(g1,g2, nrow = 2, ncol = 1)
# Linearity
g3 = ggplot(HSB, aes(x = math, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science")
g4 = ggplot(HSB, aes(x = math, y = science, color = ses)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science W/ SES")
ggarrange(g3,g4, nrow = 2, ncol = 1)
# Equal SD
par(mfrow = c(2,2))
plot(fit)
# Independence
# We are assuming that each of the column values are independent of one another.
## Step 5 INTERPRETATION
summary(fit)
confint(fit)
# mu(science | SES = 1, Math) = 16.59 + .633 * Math
# mu(science | SES = 2, Math) = 18.67 + .633 * Math
# mu(science | SES = 3, Math) = 19.91 + .633 * Math
# Change between SES 2 <-> 3 does not have significant impact on the science
# score, with a p value of .3417. A change between SES 3 -> 1, has a significant
# impact on score, with a p value of .0348, and a 95% CI of (-6.4 , -.24).
# This is an observational study only, so only inferences to the population can
# be made.
g5 = ggplot(HSB,aes(x = math, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Math")
g6 = ggplot(HSB,aes(x = science, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Science")
g7 = ggplot(HSB,aes(x = read, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Reading")
g8 = ggplot(HSB, aes(x = math, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science")
g9 = ggplot(HSB, aes(x = read, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Reading V Science")
ggarrange(g5,g6,g7,g8,g9, nrow = 3, ncol = 2)
## Step 2 MODEL
# mu(Science | Math, Reading) = Bo + B1 Math + B2 Reading
fit2 = lm(science ~ math + read, data = HSB)
## Step 3 INTERPRETATION
summary(fit2)
confint(fit2)
# mu(Science | Math, Reading) = 11.62 + .402 Math + .365 Reading
# Both reading and math scores individually have an about equal effect
# on the science scores, a fun interpretation to make from this model is that
# if a student somehow gets 0's on both math and reading, the student
# (according to this model) will probably have an 11.62 in science.
# This is an observational study only, so only inferences to the population can
# be made.
library(tidyverse)
library(dplyr)
library(car)
library(readr)
library(readxl)
library(ggplot2)
library(ggpubr)
library(ggcorrplot)
library(multcomp)
library(pairwiseCI)
library(effectsize)
library(investr)
library(broom)
################## ################## ################## ################## FLS
HSB = read_csv("DS6371/Week 12/Data/HSB2.csv")
HSB$ses = as.factor(HSB$ses)
### Question 1
## Step 1 PLOT
correlation = round(cor(HSB[,7:11]),1)
ggcorrplot(correlation, type = "lower",lab = TRUE)
ggplot(HSB, aes(x = math, y = science, color = ses)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science W/ SES")
## Step 2/3 MODEL
# mu(science|ses, math) = Bo + B1 SES(1) + B2 SES(2) + B3 Math
summary(HSB)
head(HSB)
HSB = within(HSB, ses <- relevel(ses, ref = 3))
fit = lm(science ~ math + ses, data = HSB)
summary(fit)
## Step 4 ASSUMPTIONS
# Normality
g1 = ggplot(HSB,aes(x = math, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Math")
g2 = ggplot(HSB,aes(x = science, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Science")
ggarrange(g1,g2, nrow = 2, ncol = 1)
# Linearity
g3 = ggplot(HSB, aes(x = math, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science")
g4 = ggplot(HSB, aes(x = math, y = science, color = ses)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science W/ SES")
ggarrange(g3,g4, nrow = 2, ncol = 1)
# Equal SD
par(mfrow = c(2,2))
plot(fit)
# Independence
# We are assuming that each of the column values are independent of one another.
## Step 5 INTERPRETATION
summary(fit)
confint(fit)
# mu(science | SES = 1, Math) = 16.59 + .633 * Math
# mu(science | SES = 2, Math) = 18.67 + .633 * Math
# mu(science | SES = 3, Math) = 19.91 + .633 * Math
# Change between SES 2 <-> 3 does not have significant impact on the science
# score, with a p value of .3417. A change between SES 3 -> 1, has a significant
# impact on score, with a p value of .0348, and a 95% CI of (-6.4 , -.24).
# This is an observational study only, so only inferences to the population can
# be made.
### Question 2
## Step 1 PLOT/ADRESS ASSUMPTIONS
g5 = ggplot(HSB,aes(x = math, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Math")
g6 = ggplot(HSB,aes(x = science, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Science")
g7 = ggplot(HSB,aes(x = read, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Reading")
g8 = ggplot(HSB, aes(x = math, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science")
g9 = ggplot(HSB, aes(x = read, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Reading V Science")
ggarrange(g5,g6,g7,g8,g9, nrow = 3, ncol = 2)
## Step 2 MODEL
# mu(Science | Math, Reading) = Bo + B1 Math + B2 Reading
fit2 = lm(science ~ math + read, data = HSB)
## Step 3 INTERPRETATION
summary(fit2)
confint(fit2)
# mu(Science | Math, Reading) = 11.62 + .402 Math + .365 Reading
# Both reading and math scores individually have an about equal effect
# on the science scores, a fun interpretation to make from this model is that
# if a student somehow gets 0's on both math and reading, the student
# (according to this model) will probably have an 11.62 in science.
# This is an observational study only, so only inferences to the population can
# be made.
################## ################## ################## ################## HW
library(tidyverse)
library(dplyr)
library(car)
library(readr)
library(readxl)
library(ggplot2)
library(ggpubr)
library(ggcorrplot)
library(multcomp)
library(pairwiseCI)
library(effectsize)
library(investr)
library(broom)
################## ################## ################## ################## FLS
HSB = read_csv("DS6371/Week 12/Data/HSB2.csv")
HSB$ses = as.factor(HSB$ses)
### Question 1
## Step 1 PLOT
correlation = round(cor(HSB[,7:11]),1)
ggcorrplot(correlation, type = "lower",lab = TRUE)
ggplot(HSB, aes(x = math, y = science, color = ses)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science W/ SES")
## Step 2/3 MODEL
# mu(science|ses, math) = Bo + B1 SES(1) + B2 SES(2) + B3 Math
summary(HSB)
head(HSB)
# RELEVEL (REFERENCE)
HSB = within(HSB, ses <- relevel(ses, ref = 3))
fit = lm(science ~ math + ses, data = HSB)
summary(fit)
## Step 4 ASSUMPTIONS
# Normality
g1 = ggplot(HSB,aes(x = math, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Math")
g2 = ggplot(HSB,aes(x = science, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Science")
ggarrange(g1,g2, nrow = 2, ncol = 1)
# Linearity
g3 = ggplot(HSB, aes(x = math, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science")
g4 = ggplot(HSB, aes(x = math, y = science, color = ses)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science W/ SES")
ggarrange(g3,g4, nrow = 2, ncol = 1)
# Equal SD
par(mfrow = c(2,2))
plot(fit)
# Independence
# We are assuming that each of the column values are independent of one another.
## Step 5 INTERPRETATION
summary(fit)
confint(fit)
# mu(science | SES = 1, Math) = 16.59 + .633 * Math
# mu(science | SES = 2, Math) = 18.67 + .633 * Math
# mu(science | SES = 3, Math) = 19.91 + .633 * Math
# Change between SES 2 <-> 3 does not have significant impact on the science
# score, with a p value of .3417. A change between SES 3 -> 1, has a significant
# impact on score, with a p value of .0348, and a 95% CI of (-6.4 , -.24).
# This is an observational study only, so only inferences to the population can
# be made.
### Question 2
## Step 1 PLOT/ADRESS ASSUMPTIONS
g5 = ggplot(HSB,aes(x = math, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Math")
g6 = ggplot(HSB,aes(x = science, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Science")
g7 = ggplot(HSB,aes(x = read, fill = ses)) +
geom_histogram(color = "black", bins = 10, position = "identity", alpha = .5) +
scale_fill_manual(values=c("#6c1d68", "#beb7df", "#b6d7de")) +
labs(x = "", title = "Reading")
g8 = ggplot(HSB, aes(x = math, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Math V Science")
g9 = ggplot(HSB, aes(x = read, y = science)) + geom_point() + geom_smooth(se = F) +
labs(title = "Reading V Science")
ggarrange(g5,g6,g7,g8,g9, nrow = 3, ncol = 2)
## Step 2 MODEL
# mu(Science | Math, Reading) = Bo + B1 Math + B2 Reading
fit2 = lm(science ~ math + read, data = HSB)
## Step 3 INTERPRETATION
summary(fit2)
confint(fit2)
# mu(Science | Math, Reading) = 11.62 + .402 Math + .365 Reading
# Both reading and math scores individually have an about equal effect
# on the science scores, a fun interpretation to make from this model is that
# if a student somehow gets 0's on both math and reading, the student
# (according to this model) will probably have an 11.62 in science.
# This is an observational study only, so only inferences to the population can
# be made.
################## ################## ################## ################## HW
Mammal <- read_csv("DS6371/Week 12/Data/Mammal Prob 22.csv")
Brain <- read_csv("DS6371/Week 12/Data/Brain.csv")
summary(Brain)
Brain$Species = as.factor(Brain$Species)
summary(Brain)
Brain <- read_csv("DS6371/Week 12/Data/Brain.csv")
summary(Brain)
Mammal <- read_csv("DS6371/Week 12/Data/Brain.csv")
g10 = ggplot(Mammal, aes(x = Gestation, y = Brain)) + geom_point() + geom_smooth(se = F) +
labs(title = "Gestation V Brain")
g11 = ggplot(Mammal, aes(x = Litter, y = Brain)) + geom_point() + geom_smooth(se = F) +
labs(title = "Litter V Brain")
ggarrange(g10,g11, nrow = 1, ncol = 2)
g10 = ggplot(Mammal, aes(x = Gestation, y = Brain)) + geom_point() + geom_smooth(se = F) +
labs(title = "Gestation V Brain")
g11 = ggplot(Mammal, aes(x = Litter, y = Brain)) + geom_point() + geom_smooth(se = F) +
labs(title = "Litter V Brain")
g12 = ggplot(Mammal, aes(x = Gestation, y = log(Brain))) + geom_point() + geom_smooth(se = F) +
labs(title = "Gestation V Brain")
g13 = ggplot(Mammal, aes(x = Litter, y = log(Brain))) + geom_point() + geom_smooth(se = F) +
labs(title = "Litter V Brain")
ggarrange(g10,g11,g12,g13, nrow = 2, ncol = 2)
g10 = ggplot(Mammal, aes(x = Gestation, y = Brain)) + geom_point() + geom_smooth(se = F) +
labs(title = "Gestation V Brain")
g11 = ggplot(Mammal, aes(x = Litter, y = Brain)) + geom_point() + geom_smooth(se = F) +
labs(title = "Litter V Brain")
g12 = ggplot(Mammal, aes(x = log(Gestation), y = log(Brain))) + geom_point() + geom_smooth(se = F) +
labs(title = "Gestation V Brain")
g13 = ggplot(Mammal, aes(x = log(Litter), y = log(Brain))) + geom_point() + geom_smooth(se = F) +
labs(title = "Litter V Brain")
ggarrange(g10,g11,g12,g13, nrow = 2, ncol = 2)
g13 = ggplot(Mammal, aes(x = log(Litter), y = log(Brain))) + geom_point() + geom_smooth(method = lm, se = F) +
labs(title = "Log(Litter) V Log(Brain)")
ggarrange(g10,g11,g12,g13, nrow = 2, ncol = 2)
g10 = ggplot(Mammal, aes(x = Gestation, y = Brain)) + geom_point() + geom_smooth(method = lm, se = F) +
labs(title = "Gestation V Brain")
g11 = ggplot(Mammal, aes(x = Litter, y = Brain)) + geom_point() + geom_smooth(method = lm, se = F) +
labs(title = "Litter V Brain")
g12 = ggplot(Mammal, aes(x = log(Gestation), y = log(Brain))) + geom_point() + geom_smooth(method = lm, se = F) +
labs(title = "Log(Gestation) V Log(Brain)")
g13 = ggplot(Mammal, aes(x = log(Litter), y = log(Brain))) + geom_point() + geom_smooth(method = lm, se = F) +
labs(title = "Log(Litter) V Log(Brain)")
ggarrange(g10,g11,g12,g13, nrow = 2, ncol = 2)
LogMammal = Mammal %>% mutate(across(c(Brain, Body, Gestation, Litter)), function(x) log(x))
LogMammal = Mammal %>% mutate(across(c(Brain, Body, Gestation, Litter)), log(x))
LogMammal = data.frame()
LogMammal = Mammal
LogMammal[,2:5] = log(LogMammal[,2:5])
summary(LogMammal)
fit3 = lm(Brain ~ Gestation + Litter, data = LogMammal)
summary(fit3)
fit3 = lm(Brain ~ Body + Gestation + Litter, data = LogMammal)
summary(fit3)
fit3 = lm(Brain ~ Gestation + Body + Litter, data = LogMammal)
summary(fit3)
par(mfrow = c(2,2))
plot(fit3)
LogMammal = Mammal
LogMammal[,2:5] = log(LogMammal[,2:5])
summary(LogMammal)
fit3 = lm(Brain ~ Gestation + Body + Litter, data = LogMammal)
summary(fit3)
par(mfrow = c(2,1))
plot(fit3)
par(mfrow = c(1,2))
plot(fit3)
par(mfrow = c(1,3))
plot(fit3)
library(tidyverse)
library(dplyr)
library(car)
library(readr)
library(readxl)
library(knitr)
library(ggplot2)
library(ggpubr)
library(ggcorrplot)
library(stringr)
library(multcomp)
library(pairwiseCI)
library(effectsize)
library(investr)
library(broom)
library(olsrr)
setwd("D:/School/GitHub/MSDS_6371_Stat_Foundations/FinalProject")
FullData = read.csv("Data/train.csv", na.strings = "NA", strip.white = T)
Clean_FullData = FullData
Submission_TestData  = read.csv("Data/test.csv", na.strings = "NA", strip.white = T)
####################################### Data Cleaning
summary(Clean_FullData)
# Test if na.strings worked
# There are 81 NA's in the column BM "GarageCond" according to Excel
sum(is.na(Clean_FullData$GarageCond))
# R counted 81 na's, therefore it worked.
# This is a loop that will go through the columns and decide
# whether to delete the column based off of the amount of na's. Then it will
# go through each row and eleminate the row if it has more than 1 na.
yCol = 0
yRow = 0
for (i in 1:length(Clean_FullData)){
x = sum(is.na(Clean_FullData[,i])) / length(Clean_FullData[,i])
if (x > 0.3150685){ # 1460 - (.3150685 * 1460) = 1000
yCol = append(yCol,i)
}
}
yCol
length(yCol)
Clean_FullData = subset(Clean_FullData, select = -yCol)
for (i in 1:nrow(Clean_FullData)){
x = as.numeric(rowSums(is.na(Clean_FullData[i,])))
if (x > 0){
yRow = append(yRow,i)
}
}
yRow
length(yRow)
Clean_FullData = Clean_FullData[-yRow,]
# Now that the dataset is cleaned
rm(i,x,yCol,yRow)
summary(Clean_FullData)
dim(Clean_FullData)
# We can see that there are 76 variables, and 1094 rows, where each row has
# complete information on a house. This sample is more than plenty to configure
# a model.
Clean_FullData$Neighborhood = as.factor(Clean_FullData$Neighborhood)
Clean_FullData$YrSold = as.factor(Clean_FullData$YrSold)
####################################### Data Selection // Analysis Question 1
pattern = c("NAmes","Edwards","BrkSide")
AQ1_Data = Clean_FullData %>% dplyr::select(Neighborhood,GrLivArea,SalePrice) %>%
filter(grepl(paste(pattern, collapse="|"), Neighborhood)) %>%
mutate(GrLivArea = round(GrLivArea / 100))
summary(AQ1_Data)
## Plotting the data
ggplot(AQ1_Data, aes(x = GrLivArea, y = log(SalePrice))) + geom_point(aes(color = Neighborhood), alpha = .8) +
geom_smooth(method='lm', se = F, color = 'black')
## Model
AQ1Model = lm((log(SalePrice)~GrLivArea+Neighborhood+Neighborhood*GrLivArea),data = AQ1_Data)
summary(AQ1Model)
par(mfrow = c(2,2))
plot(AQ1Model)
par(mfrow = c(1,1))
# Looking at the plots, it's clear to see that there are points that are neccesary
# to remove. Looking at Resids V Lev, we can see that are points that should be
# looked at.
# The ADJ r^2 value seems pretty low, at .4206, let see if removing the points mentioned
# will increase it.
OutRem_AQ1_Data = AQ1_Data
OutRem_AQ1_Data = OutRem_AQ1_Data[-c(70,95,119,136,248,262),]
AQ1Model = lm((log(SalePrice)~GrLivArea+Neighborhood+Neighborhood*GrLivArea),data = OutRem_AQ1_Data)
summary(AQ1Model)
par(mfrow = c(2,2))
plot(AQ1Model)
par(mfrow = c(1,1))
# Okay, these graphs look a lot better, and the ADJ R^2, went up to .49. The model still isn't
# great, but that's also because of the exclusion of so many other variables.
# delete later
#
# quick note on log(y) transform
# https://www.real-statistics.com/multiple-regression/multiple-regression-log-transformations/
#
# build model here
# Also need to do assumptions formally
par(mfrow = c(2,2))
plot(AQ1Model)
par(mfrow = c(1,1))
####################################### Data Selection // Analysis Question 2
CorrMatData = Clean_FullData %>% dplyr::select(where(is.numeric))
CleanCorrMatrix = round(cor(CorrMatData), 1)
ggcorrplot(CleanCorrMatrix, hc.order = TRUE, type = "lower", outline.col = "white")
ggplot(Clean_FullData, aes(x=YrSold, y=log(SalePrice), fill = YrSold)) + geom_boxplot() +
theme(legend.position="none") +
scale_fill_brewer(palette="Dark2") +
labs(title = "Log(SalePrice) Over the Years)", x = "Year Sold", y = "Log(SalePrice)")
length(Clean_FullData)
length(Clean_FullData[,2])
ggplot(AQ1_Data, aes(x = GrLivArea, y = log(SalePrice))) + geom_point(aes(color = Neighborhood), alpha = .8) +
geom_smooth(method='lm', se = F, color = 'black') + xlim(5,35)
CorrMatData = Clean_FullData %>% dplyr::select(where(is.numeric))
CleanCorrMatrix = round(cor(CorrMatData), 1)
ggcorrplot(CleanCorrMatrix, hc.order = TRUE, type = "lower", outline.col = "white")
ggplot(Clean_FullData, aes(x=YrSold, y=log(SalePrice), fill = YrSold)) + geom_boxplot() +
theme(legend.position="none") +
scale_fill_brewer(palette="Dark2") +
labs(title = "Log(SalePrice) Over the Years)", x = "Year Sold", y = "Log(SalePrice)")
OutRem_AQ1_Data %>% filter(grepl("NAmes", Neighborhood)) %>% ggplot(AQ1_Data, aes(x = GrLivArea, y = log(SalePrice))) + geom_point(aes(color = Neighborhood), alpha = .8) +
geom_smooth(method='lm', se = F, color = 'black')
OutRem_AQ1_Data %>% filter(grepl("NAmes", Neighborhood)) %>% ggplot(AQ1_Data, aes(x = GrLivArea, y = log(SalePrice))) + geom_point()
OutRem_AQ1_Data %>% filter(grepl("NAmes", Neighborhood)) %>% ggplot(OutRem_AQ1_Data, aes(x = GrLivArea, y = log(SalePrice))) + geom_point()
OutRem_AQ1_Data %>% filter(grepl("NAmes", Neighborhood)) %>% ggplot(OutRem_AQ1_Data, aes(x = GrLivArea, y = log(SalePrice))) + geom_point()
RShiny_NAmes = OutRem_AQ1_Data %>% filter(grepl("NAmes", Neighborhood))
ggplot(RShiny_NAmes, aes(x = GrLivArea, y = log(SalePrice))) + geom_point()
Clean_FullData %>% filter(grepl("NAmes", Neighborhood)) %>% ggplot(aes(x = GrLivArea, y = log(SalePrice))) + geom_point() + labs(title = "")
Clean_FullData %>% filter(grepl("NAmes", Neighborhood)) %>% ggplot(aes(x = GrLivArea, y = log(SalePrice))) + geom_point() + labs(title = "North Ames; Sales Price VS Square Footage")
Clean_FullData %>% filter(grepl("NAmes", Neighborhood)) %>% ggplot(aes(x = GrLivArea, y = SalePrice)) + geom_point() + labs(title = "North Ames; Sales Price VS Square Footage", x = "Square Footage", y = "Sales Price")
shiny::runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
runApp('RShiny')
